## Abstract
In semi-supervised learning (SSL), consistency learning and contrastive learning are key strategies for improving model performance, where the former encourages the model to maintain consistent predictions across different views and perturbations, whereas the latter helps the model learn more discriminative feature representations. By combining the complementary characteristics of consistency learning and contrastive learning, the model's performance can be further enhanced.} In this paper, a novel semi-supervised medical image segmentation model is proposed, based on multi-view cross-consistency and multi-scale cross-layer contrastive learning (MCMCCL). The former can reduce inconsistencies in predictions across different views and explore a broader perturbation space, while the latter can enhance the richness and diversity of extracted features. Their complementary characteristics is crucial for enhancing the segmentation performance. The novel image-level consistency based on cross bidirectional copy-paste (CBCP) is proposed to enhance the model's ability to capture the overall distribution of unlabeled data. The multi-scale cross-layer contrastive learning (MCCL) strategy is proposed to allow the model to learn meaningful feature representations without relying on negative samples across multi-scale feature maps. The CNN and Transformer models are jointly trained using cross-teaching to seamlessly integrate both strategies and further enhance the model's performance. The experiments are conducted on three publicly available medical image datasets, ACDC, PROMISE12, and LiTS, and the results confirm the effectiveness of our model. In particular, the experiment conducted on the PROMISE12 dataset with 20% labeled samples achieves a Dice score only 0.47 lower than the fully supervised approach, significantly narrowing the gap between semi-supervised and fully supervised learning.
